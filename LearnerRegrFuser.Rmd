```{r}
# Load the required packages
library(mlr3)
library(mlr3learners)
library(mlr3misc)
library(fuser)
library(R6)
library(paradox)
library(kknn)
```

```{r}
N <- 300
abs.x <- 20
set.seed(1)
x.vec <- runif(N, -abs.x, abs.x)
str(x.vec)

library(data.table)
(task.dt <- data.table(
  x=x.vec,
  y = sin(x.vec)+rnorm(N,sd=0.5)))

reg.task <- mlr3::TaskRegr$new("sin", task.dt, target="y")

task.dt[, sample_group := rep(1:3, l=.N)][]
table(group.tab <- task.dt$sample_group)

(group.task <- reg.task <- mlr3::TaskRegr$new(
  "sin", task.dt, target="y"
)$set_col_roles("sample_group",c("group")))
```

```{r}
ordered_features = function(task, learner) {
  cols = names(learner$state$data_prototype)
  task$data(cols = intersect(cols, task$feature_names))
}

# Define a new learner class that inherits from LearnerRegr
LearnerRegrFuser <- R6Class("LearnerRegrFuser",
  inherit = LearnerRegr,
  public = list( 
    initialize = function() {
       ps = ps(
          lambda = p_dbl(lower = 0, upper = 1, default = 0.01, tags = "train"),
          gamma = p_dbl(lower = 0, upper = 1, default = 0.01, tags = "train"),
          tol = p_dbl(lower = 0, upper = 1, default = 9e-5, tags = "train"),
          num.it = p_int(default = 500, tags = "train"),
          intercept = p_lgl(default = TRUE, tags = "train"),
          scaling = p_lgl(default = FALSE, tags = "train")
       )
       ps$values = list(lambda = 0.01, gamma = 0.01, 
                        tol = 9e-5, num.it = 5000,
                        intercept = TRUE, scaling = FALSE)
       super$initialize(
          id = "regr.fuser",
          param_set = ps,
          feature_types = c("logical", "integer", "numeric", "factor"),
          label = "Fuser",
          packages = c("mlr3learners", "fuser")
       )
    }
  ),
  private = list(
    .train = function(task) {
      X <- as.matrix(task$data(cols = task$feature_names))
      y <- as.matrix(task$data(cols = task$target_names))
      k <- as.numeric(length(unique(task$groups$group))) # number of groups
      n.group <- as.numeric(table(task$groups$group)["1"]) # samples per group (for first group)
      # Table of samples per group
      n.groups <- table(task$groups$group)
      n.groups
      
      # Create group indicators
      group_ind <- task$groups$group
      group_ind

      G <- matrix(1, k, k) 
      print("k")
      print(k)
      
      print("n.group")
      print(n.group)
      
      print("G")
      print(G)
      
      pv <- self$param_set$get_values(tags = "train")
      lambda <- pv$lambda
      gamma <- pv$gamma
      tol <- pv$tol
      num.it <- pv$num.it
      intercept <- pv$intercept
      scaling <- pv$scaling
  
      # Create the matrix with appropriate dimensions
      y = matrix(y, nrow = n.group, ncol = k, byrow = TRUE)
      X = apply(X, 2, as.numeric)
      
      beta.estimate = fusedLassoProximal(X, y, group_ind, 
                                           lambda = lambda, 
                                           G = G, 
                                           gamma = gamma,
                                           tol = tol, 
                                           num.it = num.it,
                                           intercept = FALSE,
                                           scaling = scaling) 
      
      print("got here 2")
      # Store the coefficients in the learner
      self$model = list(beta = beta.estimate, 
                        formula = task$formula(),
                        data = task$data(),
                        pv = pv,
                        groups = group_ind)
      
      print("got here 2")
      self$model
    },
    .predict = function(task) {
      X = ordered_features(task, self)
      X = as.matrix(task$data(cols = task$feature_names))
      X = apply(X, 2, as.numeric)
      k <- as.numeric(length(unique(task$groups$group)))  # number of groups
      n.group <- as.numeric(table(task$groups$group)["1"]) # samples per group  
      # Extract the coefficients and groups from the learner
      beta = self$model$beta
      print("typeof(beta)")
      print(typeof(beta))
      print("beta")
      print(beta)
      X.list <- lapply(1:k, function(k.i) X[((k.i - 1)*n.group+1):(k.i*n.group), ])
      y.predict = sapply(1:k, function(k.i) X.list[[k.i]] %*% beta[,k.i]) 
      y.predict = c(y.predict)
      list(response = y.predict)
    }
  )
)
# Register the new learner
mlr_learners$add("regr.fuser", LearnerRegrFuser)

# Load the Boston house price dataset
data("BostonHousing", package = "mlbench")
BostonHousing <- BostonHousing[1:300, ]
BostonHousing$chas <- NULL
BostonHousing$sample_group <- rep(1:3, length.out = nrow(BostonHousing))
#BostonHousing$sample_group <- sample(1:3, size = nrow(BostonHousing), replace = TRUE)


task = TaskRegr$new(id = "boston", 
                    backend = BostonHousing, 
                    target = "medv")$set_col_roles("sample_group", c("group"))
learner = lrn("regr.fuser", 
              lambda = 0.001, 
              gamma = 0.001
              )
learner$train(task)

pred_task = TaskRegr$new(id = "boston", 
                    backend = BostonHousing[1:210, ], 
                    target = "medv")$set_col_roles("sample_group", c("group","stratum"))
learner$predict(pred_task)

#learner = lrn("regr.fuser", 
#              lambda = 0.001, 
#              gamma = 0.001)
# Create a learner instance
#learner$train(group.task)
#learner$predict(group.task)
```



```{r}
learner = lrn("regr.fuser", 
              lambda = 0.001, 
              gamma = 0.001, 
              groups = groups, 
              G = G,
              k = k,
              n.group = n.group)
# Create a learner instance
learner$train(group.task)
learner$predict(group.task)

```
