```{r}
# Load the required packages
library(mlr3)
library(mlr3learners)
library(mlr3misc)
library(fuser)
library(R6)
library(paradox)
library(kknn)
```

```{r}

ordered_features = function(task, learner) {
  cols = names(learner$state$data_prototype)
  task$data(cols = intersect(cols, task$feature_names))
}

# Define a new learner class that inherits from LearnerRegr
LearnerRegrFuser <- R6Class("LearnerRegrFuser",
  inherit = LearnerRegr,
  public = list( 
    initialize = function() {
       params = list(
          ParamDbl$new("lambda", lower = 0, upper = 1),
          ParamDbl$new("gamma", lower = 0, upper = 1, default = 0.01),
          ParamUty$new(id = "groups", default = NULL, tags = ""),
          ParamUty$new(id = "G", default = NULL, tags = ""),
          ParamInt$new(id = "k", default = 5, tags = ""),
          ParamInt$new(id = "n.group", default = 100, tags = "")
        )
      ps = ParamSet$new(params = params)
      super$initialize(
        id = "regr.fuser",
        param_set = ps,
        feature_types = c("logical", "integer", "numeric", "factor"),
        label = "Fuser",
        packages = c("mlr3learners", "fuser")
      )
    }
  ),
  private = list(
    .train = function(task) {
      X = as.matrix(task$data(cols = task$feature_names))
      y = as.matrix(task$data(cols = task$target_names))
      pv = self$param_set$get_values()
      lambda = pv$lambda
      gamma = pv$gamma
      groups = pv$groups
      G = pv$G
      k = as.integer(pv$k) 
      n.group = as.integer(pv$n.group)
      
      y = matrix(y, nrow = n.group, ncol = k, byrow = TRUE)
      X = apply(X, 2, as.numeric)
      beta.estimate = fusedLassoProximal(X, y, groups, 
                                          lambda = lambda, 
                                           tol = 9e-5, 
                                           gamma = gamma,
                                           G = G, 
                                           intercept = FALSE,
                                           scaling = FALSE,
                                           num.it = 5000) 
      
      # Store the coefficients in the learner
      self$model = list(beta = beta.estimate, 
                        formula = task$formula(),
                        data = task$data(),
                        pv = pv,
                        groups = groups)
      self$model
    },
    .predict = function(task) {
      X = ordered_features(task, self)
      X = as.matrix(task$data(cols = task$feature_names))
      X = apply(X, 2, as.numeric)
      k = 5
      n.group = 100
      # Extract the coefficients and groups from the learner
      beta = self$model$beta
      X.list <- lapply(1:k, function(k.i) X[((k.i - 1)*n.group+1):(k.i*n.group), ])
      y.predict = sapply(1:k, function(k.i) X.list[[k.i]] %*% beta[,k.i]) 
      y.predict = c(y.predict)
      list(response = y.predict)
    }
  )
)
# Register the new learner
mlr_learners$add("regr.fuser", LearnerRegrFuser)

k = 5 # number of groups
n.group = 100 # number of samples per group
groups = rep(1:k, each=n.group) # group indicators
G = matrix(1, k, k) 

# Load the Boston house price dataset
data("BostonHousing", package = "mlbench")
BostonHousing = BostonHousing[1:500, ]
BostonHousing$chas <- NULL
task = TaskRegr$new(id = "boston", 
                    backend = BostonHousing, 
                    target = "medv")
learner = lrn("regr.fuser", 
              lambda = 0.001, 
              gamma = 0.001, 
              groups = groups, 
              G = G,
              k = k,
              n.group = n.group
              )
# Create a learner instance
learner$train(task)
learner$predict(task)
```
