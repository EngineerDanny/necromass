```{r}
# Load the required packages
library(mlr3)
library(mlr3learners)
library(mlr3misc)
library(fuser)
library(R6)
library(paradox)
library(kknn)
```

```{r}
N <- 300
abs.x <- 20
set.seed(1)
x.vec <- runif(N, -abs.x, abs.x)
str(x.vec)

library(data.table)
(task.dt <- data.table(
  x=x.vec,
  y = sin(x.vec)+rnorm(N,sd=0.5)))

reg.task <- mlr3::TaskRegr$new("sin", task.dt, target="y")

task.dt[, sample_group := rep(1:3, l=.N)][]
table(group.tab <- task.dt$sample_group)

(group.task <- reg.task <- mlr3::TaskRegr$new(
  "sin", task.dt, target="y"
)$set_col_roles("sample_group",c("group")))
```

```{r}

ordered_features = function(task, learner) {
  cols = names(learner$state$data_prototype)
  task$data(cols = intersect(cols, task$feature_names))
}

# Define a new learner class that inherits from LearnerRegr
LearnerRegrFuser <- R6Class("LearnerRegrFuser",
  inherit = LearnerRegr,
  public = list( 
    initialize = function() {
       ps = ps(
          lambda = p_dbl(lower = 0, upper = 1, default = 0.01, tags = "train"),
          gamma = p_dbl(lower = 0, upper = 1, default = 0.01, tags = "train"),
          tol = p_dbl(lower = 0, upper = 1, default = 9e-5, tags = "train"),
          num.it = p_int(lower = 1, upper = 1000000, default = 5000, tags = "train")
       )
       
       ps$values = list(lambda = 0.01, gamma = 0.01, tol = 9e-5, num.it = 5000)
  
      super$initialize(
        id = "regr.fuser",
        param_set = ps,
        feature_types = c("logical", "integer", "numeric", "factor"),
        label = "Fuser",
        packages = c("mlr3learners", "fuser")
      )
      
    #  lapply(self$param_set$params, function(param) {
    #  value <- self$param_set$values[[param$id]]
    #  if (is.null(value)) {
    #    self$param_set$values[[param$id]] <- param$default
    #    }
    #  })
      
      
    }
  ),
  private = list(
    .train = function(task) {
      X = as.matrix(task$data(cols = task$feature_names))
      y = as.matrix(task$data(cols = task$target_names))
      
      k <- as.numeric(length(unique(task$groups$group))) # number of groups
      n.group <- as.numeric(table(task$groups$group)["1"]) # samples per group  
      group_ind = rep(1:k, each=n.group) # group indicators
      G = matrix(1, k, k) 
      
      print("k")
      print(k)
      
      print("n.group")
      print(n.group)
      
      print("G")
      print(G)
      
      pv = self$param_set$get_values(tags = "train")
      lambda = pv$lambda
      gamma = pv$gamma
      tol = pv$tol
      num.it = pv$num.it
      
      print("self$param_set")
      print(self$param_set$get)
      
      print("num.it")
      print(num.it)
  
      y = matrix(y, nrow = n.group, ncol = k, byrow = TRUE)
      X = apply(X, 2, as.numeric)
      beta.estimate = fusedLassoProximal(X, y, group_ind, 
                                           lambda = lambda, 
                                           G = G, 
                                           gamma = gamma,
                                           tol = tol, 
                                           num.it = num.it,
                                           intercept = FALSE,
                                           scaling = FALSE
                                         ) 
      # Store the coefficients in the learner
      self$model = list(beta = beta.estimate, 
                        formula = task$formula(),
                        data = task$data(),
                        pv = pv,
                        groups = group_ind)
      self$model
    },
    .predict = function(task) {
      X = ordered_features(task, self)
      X = as.matrix(task$data(cols = task$feature_names))
      X = apply(X, 2, as.numeric)
      k <- as.numeric(length(unique(task$groups$group)))  # number of groups
      n.group <- as.numeric(table(task$groups$group)["1"]) # samples per group  
      # Extract the coefficients and groups from the learner
      beta = self$model$beta
      print("typeof(beta)")
      print(typeof(beta))
      
      print("beta")
      print(beta)
      
      X.list <- lapply(1:k, function(k.i) X[((k.i - 1)*n.group+1):(k.i*n.group), ])
      y.predict = sapply(1:k, function(k.i) X.list[[k.i]] %*% beta[,k.i]) 
      y.predict = c(y.predict)
      list(response = y.predict)
    }
  )
)
# Register the new learner
mlr_learners$add("regr.fuser", LearnerRegrFuser)



# Load the Boston house price dataset
data("BostonHousing", package = "mlbench")
BostonHousing <- BostonHousing[1:300, ]
BostonHousing$chas <- NULL
BostonHousing$sample_group <- rep(1:3, length.out = nrow(BostonHousing))

task = TaskRegr$new(id = "boston", 
                    backend = BostonHousing, 
                    target = "medv")$set_col_roles("sample_group", c("group"))
learner = lrn("regr.fuser", 
              lambda = 0.001, 
              gamma = 0.001 
              )
print(learner)
# Create a learner instance
learner$train(task)

pred_task = TaskRegr$new(id = "boston", 
                    backend = BostonHousing[1:210, ], 
                    target = "medv")$set_col_roles("sample_group", c("group","stratum"))
learner$predict(pred_task)



#learner = lrn("regr.fuser", 
#              lambda = 0.001, 
#              gamma = 0.001)
# Create a learner instance
#learner$train(group.task)
#learner$predict(group.task)


```
```{r}

#' @title k-Nearest-Neighbor Regression Learner
#'
#' @name mlr_learners_regr.kknn
#'
#' @description
#' k-Nearest-Neighbor regression.
#' Calls [kknn::kknn()] from package \CRANpkg{kknn}.
#'
#' @section Initial parameter values:
#' - `store_model`:
#'   - See note.
#'
#' @template note_kknn
#'
#' @templateVar id regr.kknn
#' @template learner
#'
#' @references
#' `r format_bib("hechenbichler_2004", "samworth_2012", "cover_1967")`
#'
#' @export
#' @template seealso_learner
#' @template example
LearnerRegrKKNN = R6Class("LearnerRegrKKNN",
  inherit = LearnerRegr,
  public = list(

    #' @description
    #' Creates a new instance of this [R6][R6::R6Class] class.
    initialize = function() {
      ps = ps(
        k           = p_int(default = 7L, lower = 1L, tags = "train"),
        distance    = p_dbl(0, default = 2, tags = "train"),
        kernel      = p_fct(c("rectangular", "triangular", "epanechnikov", "biweight", "triweight", "cos", "inv", "gaussian", "rank", "optimal"), default = "optimal", tags = "train"),
        scale       = p_lgl(default = TRUE, tags = "train"),
        ykernel     = p_uty(default = NULL, tags = "train"),
        store_model = p_lgl(default = FALSE, tags = "train")
      )

      ps$values = list(k = 7L)

      super$initialize(
        id = "regr.kknn",
        param_set = ps,
        feature_types = c("logical", "integer", "numeric", "factor", "ordered"),
        packages = c("mlr3learners", "kknn"),
        label = "k-Nearest-Neighbor",
        man = "mlr3learners::mlr_learners_regr.kknn"
      )
    }
  ),

  private = list(
    .train = function(task) {
      # https://github.com/mlr-org/mlr3learners/issues/191
      pv = self$param_set$get_values(tags = "train")
      if (pv$k >= task$nrow) {
        stopf("Parameter k = %i must be smaller than the number of observations n = %i",
          pv$k, task$nrow)
      }

      list(
        formula = task$formula(),
        data = task$data(),
        pv = pv,
        kknn = NULL
      )
    },

    .predict = function(task) {
      model = self$model
      newdata = ordered_features(task, self)
      pv = insert_named(model$pv, self$param_set$get_values(tags = "predict"))

      with_package("kknn", { # https://github.com/KlausVigo/kknn/issues/16
        p = invoke(kknn::kknn,
          formula = model$formula, train = model$data,
          test = newdata, .args = remove_named(pv, "store_model"))
      })

      if (isTRUE(pv$store_model)) {
        self$state$model$kknn = p
      }

      list(response = p$fitted.values)
    }
  )
)

#' @include aaa.R
learners[["regr.kknn"]] = LearnerRegrKKNN

```




```{r}
# Define parameters with default values
gamma_param <- ParamDbl$new("gamma", lower = 0, upper = 1, default = 0.01)
gamma_param


```

```{r}
learner = lrn("regr.fuser", 
              lambda = 0.001, 
              gamma = 0.001, 
              groups = groups, 
              G = G,
              k = k,
              n.group = n.group)
# Create a learner instance
learner$train(group.task)
learner$predict(group.task)

```
