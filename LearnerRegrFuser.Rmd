```{r}
# Load the required packages
library(mlr3)
library(mlr3learners)
library(mlr3misc)
library(fuser)
library(R6)
library(paradox)
library(kknn)
```


```{r}
LearnerRegrFuser <- R6Class("LearnerRegrFuser",
                            inherit = LearnerRegr,
                            public = list( 
                              initialize = function() {
                                ps = ps(
                                  lambda = p_dbl(0, default = 0.01, tags = "train"),
                                  gamma = p_dbl(0, default = 0, tags = "train"),
                                  tol = p_dbl(lower = 0, upper = 1, default = 1e-06, tags = "train"),
                                  num.it = p_int(default = 1000, tags = "train"),
                                  intercept = p_lgl(default = FALSE, tags = "train"),
                                  scaling = p_lgl(default = T, tags = "train")
                                )
                                ps$values = list(lambda = 0.01, gamma = 0, 
                                                 tol = 1e-06, num.it = 10000000,
                                                 intercept = FALSE, scaling = T)
                                super$initialize(
                                  id = "regr.fuser",
                                  param_set = ps,
                                  feature_types = c("logical", "integer", "numeric"),
                                  label = "Fuser",
                                  packages = c("mlr3learners", "fuser")
                                )
                              }
                            ),
                            private = list(
                              .train = function(task) {
                                # Assuming 'task' is a task object with data, feature names, and group information
                                subset_ID <- task$col_roles$subset
                                X_train <- as.matrix(task$data(cols = setdiff(task$feature_names, subset_ID)))
                                y_train <- as.matrix(task$data(cols = task$target_names))
                                group_ind <- as.matrix(task$data(cols = subset_ID))
                                #print("Task summary:")
                                #str(reg.task$col_roles)
                                #print("group_ind")
                                #print(group_ind)
                                #print(typeof(group_ind))
                                
                                #group_ind <- task$groups$group
                                #group_ind <- task$groups$subset
                                k <- as.numeric(length(unique(group_ind))) # number of groups
                                n.group <- min(table(group_ind)) # minimum samples per group across all groups
                                
                                
                                # Initialize a new vector to store the balanced group indices
                                balanced_group_ind <- integer(0)
                                
                                # Loop through each unique group and select 'n.group' indices for each
                                for (grp in unique(group_ind)) {
                                  grp_indices <- which(group_ind == grp)
                                  balanced_group_ind <- c(balanced_group_ind, sample(grp_indices, n.group))
                                }
                                
                                # Now 'balanced_group_ind' contains an equal number of indices for each group
                                group_ind <- group_ind[balanced_group_ind]
                                
                                # Print the final group index
                                #print("balanced_group_ind")
                                #print(balanced_group_ind)
                                
                                pv <- self$param_set$get_values(tags = "train")
                                
                                # Create the matrices with appropriate dimensions
                                
                                y <- matrix(y_train[balanced_group_ind], nrow = n.group, ncol = k, byrow = TRUE)
                                X <- X_train[balanced_group_ind, ]
                                
                                # Initialize glmnet_model before tryCatch
                                glmnet_model <- mlr3learners::LearnerRegrCVGlmnet$new()$train(task)$model
                                
                                tryCatch({
                                  # Use fuser::fusedLassoProximal
                                  # Generate block diagonal matrices for L2 fusion approach
                                  # transformed.data = generateBlockDiagonalMatrices(X, y, group_ind, matrix(1, k, k))
                                  # Use L2 fusion to estimate betas (with near-optimal information sharing among groups)
                                  # beta.estimate = fusedL2DescentGLMNet(transformed.data$X, transformed.data$X.fused, 
                                  #                                     transformed.data$Y, group_ind, lambda=pv$lambda,
                                  #                                     gamma=pv$gamma)
                                  # colnames(beta.estimate) = as.character(sort(unique(group_ind)))
                                  # beta.estimate = beta.estimate[,,1]
                                  # colnames(beta.estimate) = as.character(sort(unique(group_ind)))
                                  # print("beta.estimate")
                                  # print(beta.estimate)
                                  
                                  # Use fuser::fusedLassoProximal
                                  fuser_params <- fuser::fusedLassoProximal(X, y, group_ind, 
                                                                             lambda = pv$lambda, 
                                                                             G = matrix(1, k, k), 
                                                                             gamma = pv$gamma,
                                                                             tol = pv$tol, 
                                                                             num.it = 10000000,
                                                                             intercept = T,
                                                                             scaling = T)
                                  beta.estimate <- head(fuser_params, -1)
                                  intercept <- tail(fuser_params, 1)
                                  
                                  # Update self$model with both beta.estimate and glmnet_model
                                  self$model <- list(beta = beta.estimate, 
                                                     intercept = intercept,
                                                     glmnet_model = glmnet_model,
                                                     model_type = "fuser",
                                                     formula = task$formula(),
                                                     data = task$data(),
                                                     pv = pv,
                                                     groups = group_ind)
                                  
                                }, error = function(e) {
                                  print("error")
                                  print(e)
                                  # Update self$model with glmnet_model in case of error
                                  self$model <- list(glmnet_model = glmnet_model,
                                                     model_type = "glmnet",
                                                     formula = task$formula(),
                                                     data = task$data(),
                                                     pv = pv,
                                                     groups = group_ind)
                                })
                                

                                self$model
                              },
                              .predict = function(task) {
                                ordered_features = function(task, learner) {
                                  cols = names(learner$state$data_prototype)
                                  task$data(cols = intersect(cols, task$feature_names))
                                }
                                
                                subset_ID <- task$col_roles$subset
                                X_test <- as.matrix(task$data(cols = setdiff(task$feature_names, subset_ID)))
                                group_ind <- as.matrix(task$data(cols = subset_ID))
                                new_X_test = as.matrix(task$data(cols = task$feature_names))
                                X = apply(X_test, 2, as.numeric)
                                #group_ind <- task$groups$group
                               
                                beta = self$model$beta
                                intercept = self$model$intercept
                                model_type <- self$model$model_type
                                train_group_ind <- self$model$groups
                                y.predict <- rep(NA, nrow(X))
                                
                                group_names <- colnames(beta)[unique(group_ind)]
                                #print("group_names")
                                #print(group_names)
                                
                                for (name in group_names) {
                                  group_rows <- which(group_ind == name)
                                  if (length(group_rows) > 0) {
                                    X.group <- X[group_rows, , drop = FALSE]
                                    y.predict[group_rows] <- as.numeric(X.group %*% beta[, name] + intercept[, name])
                                  } else {
                                    warning(paste("No rows found for group", name))
                                  }
                                }
                                
                                
                                # Check for NAs or errors and use glmnet_model if needed
                                if (any(is.na(y.predict))) {
                                  print("Used glmnet.")
                                  #print(train_group_ind)
                                  y.predict.new <- as.vector(predict(self$model$glmnet_model, newx = new_X_test))
                                  #print("NA values detected in predictions. Falling back to glmnet.")
                                }else{
                                  print("Used normal")
                                  #print(train_group_ind)
                                  y.predict.new <- y.predict
                                }
                                #y.predict <- as.vector(predict(self$model$glmnet_model, newx = X_test))
                                # Return the predictions as a numeric vector
                                list(response = y.predict.new)
                              }
                            )
)
# Register the new learner
mlr_learners$add("regr.fuser", LearnerRegrFuser)
learner = lrn("regr.fuser")
```


```{r}
# Load the Boston house price dataset
data("BostonHousing", package = "mlbench")
BostonHousing <- BostonHousing[1:200, ]
BostonHousing$chas <- NULL
BostonHousing$sample_group <- rep(1:3, length.out = nrow(BostonHousing))
#BostonHousing$sample_group <- sample(1:3, size = nrow(BostonHousing), replace = TRUE)

task = TaskRegr$new(id = "boston", 
                    backend = BostonHousing, 
                    target = "medv")

task$col_roles$subset <- "sample_group"
task$col_roles$stratum <- "sample_group"


learner = lrn("regr.fuser")
learner$train(task)

pred_task = TaskRegr$new(id = "boston", 
                    backend = BostonHousing, 
                    target = "medv")
pred_task$col_roles$subset <- "sample_group"
pred_task$col_roles$stratum <- "sample_group"

pred_dt <-  learner$predict(pred_task)

plot(truth ~ response, as.data.table(pred_dt)  )
```

```{r}

# Load the Boston house price dataset
data("BostonHousing", package = "mlbench")
BostonHousing <- BostonHousing[1:200, ]
BostonHousing$chas <- NULL
BostonHousing$sample_group <- rep(1:3, length.out = nrow(BostonHousing))
#BostonHousing$sample_group <- sample(1:3, size = nrow(BostonHousing), replace = TRUE)

task = TaskRegr$new(id = "boston", 
                    backend = BostonHousing, 
                    target = "medv")$set_col_roles("sample_group", c("group"))

learner = mlr3learners::LearnerRegrCVGlmnet$new()
learner$train(task)

pred_task = TaskRegr$new(id = "boston", 
                    backend = BostonHousing, 
                    target = "medv")$set_col_roles("sample_group", c("group"))
pred_dt <-  learner$predict(pred_task)

plot(truth ~ response, as.data.table(pred_dt)  )

```

```{r}
library(data.table)

N <- 300
abs.x <- 20
set.seed(1)
x.mat <- matrix(runif(N * 3, -abs.x, abs.x), ncol = 3)  # Ensure X has more than two features
colnames(x.mat) <- paste0("feature", 1:3)
(task.dt <- data.table(
  x = x.mat, 
  y = sin(rowSums(x.mat)) + rnorm(N, sd = 0.5)
))
task.dt[, sample_group := rep(1:3, length.out = .N)]
table(group.tab <- task.dt$sample_group)

# Create a regression task with the grouping variable
tsk_grp_str <- mlr3::TaskRegr$new("sin", task.dt, target = "y")
tsk_grp_str$set_col_roles("sample_group", c("group", "stratum"))
fuser.learner = lrn("regr.fuser")
#fuser.learner$param_set$values$num.it <- paradox::to_tune(1, 100)
fuser.learner$param_set$values$lambda <- paradox::to_tune(0.001, 1, log=TRUE)
#fuser.learner$param_set$values$gamma <- paradox::to_tune(0.001, 1, log=TRUE)

mycv <- MyResamplingCV$new()
mycv$param_set$values$folds <- 2
#mycv$instantiate(tsk_grp_str)
#mycv$instance

grid.search.5 <- mlr3tuning::TunerGridSearch$new()
grid.search.5$param_set$values$resolution <- 5
fuser.learner.tuned <- mlr3tuning::auto_tuner(
  tuner = grid.search.5,
  learner = fuser.learner,
  resampling = mycv,
  measure = mlr3::msr("regr.mse"))

reg.learner.list <- list(
  mlr3::LearnerRegrFeatureless$new(), fuser.learner.tuned)

grouped.task.list = list(tsk_grp_str)
(same.other.grid <- mlr3::benchmark_grid(
 tsk_grp_str,
  reg.learner.list,
  mycv))

if(require(future))plan("multisession") 
bench.result <- mlr3::benchmark(same.other.grid, store_models = TRUE)
bench.result
#save(bench.result, file=cache.RData)

options(warn=2)
```


