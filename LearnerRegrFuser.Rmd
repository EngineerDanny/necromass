```{r}
# Load the required packages
library(mlr3)
library(mlr3learners)
library(fuser)
library(R6)
library(paradox)
```

```{r}

# Load the required packages
library(mlr3)
library(mlr3learners)
library(fuser)

# Define a new learner class that inherits from LearnerRegr
LearnerRegrFuser <- R6Class("LearnerRegrFuser",
  inherit = LearnerRegr,
  public = list(
    # Initialize the learner with the required parameters
    initialize = function() {
      ps = ParamSet$new(
        params = list(
          ParamDbl$new("lambda", lower = 0, upper = 1, default = 0.01),
          ParamDbl$new("gamma", lower = 0, upper = 1, default = 0.01),
          ParamFct$new("method", levels = c("RSpectra", "irlba"), default = "RSpectra")
        )
      )
      super$initialize(
        id = "regr.fuser",
        feature_types = c("integer", "numeric", "factor"),
        predict_types = c("response"),
        packages = "fuser",
        param_set = ps
      )
    },

    # Train the learner on a given task
    train_internal = function(task) {
      # Extract the data and response from the task
      x = as.matrix(task$data(cols = task$feature_names))
      y = as.matrix(task$data(cols = task$target_names))
      # Extract the groups from the task (assuming they are stored as a column named "groups")
      groups = as.factor(task$data(cols = "groups"))
      # Extract the parameters from the learner
      pars = self$param_set$get_values()
      lambda = pars$lambda
      gamma = pars$gamma
      method = pars$method
      # Encode the factor features into dummy variables
      x = model.matrix(~ . - 1, data = as.data.frame(x))
      # Remove the intercept column if present
      x = x[, !colnames(x) %in% "(Intercept)"]
      # Convert the factor groups to a numeric vector based on the desired grouping
      groups = ifelse(groups == "A", 1, 2) # Add this line
      # Generate the block diagonal matrices for the L2 fusion approach
      transformed.data = generateBlockDiagonalMatrices(x, y, groups)
      # Use L2 fusion to estimate the coefficients
      beta.estimate = fusedL2DescentGLMNet(transformed.data$X, 
                                           transformed.data$X.fused, 
                                           transformed.data$Y, 
                                           groups, 
                                           lambda = lambda, 
                                           gamma = gamma, 
                                           method = method)
      # Store the coefficients in the learner
      self$model = list(beta = beta.estimate, groups = groups)
    },

    # Predict the response for new data
    predict_internal = function(task) {
      # Extract the data from the task
      x = as.matrix(task$data(cols = task$feature_names))
      # Encode the factor features into dummy variables
      x = model.matrix(~ . - 1, data = as.data.frame(x))
      # Remove the intercept column if present
      x = x[, !colnames(x) %in% "(Intercept)"]
      # Extract the coefficients and groups from the learner
      beta = self$model$beta
      groups = self$model$groups
      # Calculate the predicted response by multiplying the data and the coefficients
      yhat = x %*% beta[, groups]
      # Return the prediction as a PredictionRegr object
      PredictionRegr$new(task = task, response = yhat)
    }
  )
)

# Register the new learner
mlr_learners$add("regr.fuser", LearnerRegrFuser)


```



```{r}
learner$task_type
task$task_type
```


```{r}
# Load the Boston house price dataset
data("BostonHousing", package = "mlbench")
# Create a regression task with the dataset
task = TaskRegr$new(id = "boston", backend = BostonHousing, target = "medv")
learner = lrn("regr.fuser", lambda = 0.1, gamma = 0.1)
learner$train(task)
```